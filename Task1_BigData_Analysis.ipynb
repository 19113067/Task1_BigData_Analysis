{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "002acd76",
   "metadata": {},
   "source": [
    "# Big Data Analysis using PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fb7085-ed0e-42bd-a85b-6f2ae38cbba9",
   "metadata": {},
   "source": [
    "COMPANY: CODTECH IT SOLUTIONS\n",
    "\n",
    "NAME: YAKKALA LAHARI\n",
    "\n",
    "INTERN ID: CT04DY2623\n",
    "\n",
    "DOMAIN: DATA ANALYTICS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe1a934-c380-449b-96ee-b219fcf063ed",
   "metadata": {},
   "source": [
    "### **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99c2b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tempfile\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col, avg, count, hour, to_timestamp, desc, when, approx_count_distinct, sum as spark_sum\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"HADOOP_HOME\"] = \"C:\\\\hadoop\"\n",
    "os.environ[\"hadoop.home.dir\"] = \"C:\\\\hadoop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa9c869-632c-4b40-b0b4-2ab6495cbb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "DATA_DIR = \"/mnt/data/nyc_yellow_taxi\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "PARQUET_URL = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\"\n",
    "PARQUET_LOCAL = os.path.join(DATA_DIR, \"yellow_tripdata_2023-01.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e168e6bc-b103-482f-8fe2-952dc847686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_if_missing(url, local_path):\n",
    "    if os.path.exists(local_path):\n",
    "        print(f\"Dataset already present at: {local_path}\")\n",
    "        return local_path\n",
    "    print(f\"Downloading dataset to {local_path} ...\")\n",
    "    import requests\n",
    "    with requests.get(url, stream=True, timeout=60) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(local_path, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "    print(\"Download completed.\")\n",
    "    return local_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "588f19c6-22ad-437b-b789-68699ac04994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_spark(app_name=\"BigData_PySpark_Analysis\", master=\"local[*]\", driver_memory=\"4g\"):\n",
    "    spark = (\n",
    "        SparkSession.builder\n",
    "        .appName(app_name)\n",
    "        .master(master)\n",
    "        .config(\"spark.driver.memory\", driver_memory)\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"200\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    print(\"Spark initialized:\", spark.sparkContext.appName)\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d0fcdff-966f-4d36-b101-32508dcb6a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parquet(spark, path):\n",
    "    print(f\"Loading parquet from: {path}\")\n",
    "    df = spark.read.parquet(path)\n",
    "    print(\"Schema:\")\n",
    "    df.printSchema()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a8e983-e8c9-4def-91da-6a20d44f7564",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c268c39c-1f21-4a56-a1e5-3a1ce484d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    if 'tpep_pickup_datetime' in df.columns and str(df.schema['tpep_pickup_datetime'].dataType).lower().startswith('string'):\n",
    "        df = df.withColumn('tpep_pickup_datetime', to_timestamp(col('tpep_pickup_datetime')))\n",
    "    df = df.dropna(subset=['tpep_pickup_datetime', 'trip_distance', 'fare_amount'])\n",
    "    df = df.filter((col('trip_distance') >= 0) & (col('fare_amount') >= 0))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a80a4c2d-3d77-43ad-aa9e-573d826aacf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_eda(df):\n",
    "    print(\"Total records:\")\n",
    "    print(df.count())\n",
    "    df = df.withColumn('pickup_hour', hour(col('tpep_pickup_datetime')))\n",
    "    trips_by_hour = df.groupBy('pickup_hour').agg(count('*').alias('trip_count')).orderBy('pickup_hour')\n",
    "    trips_by_hour.show(24, truncate=False)\n",
    "    avg_fare = df.groupBy('passenger_count').agg(avg('fare_amount').alias('avg_fare'), count('*').alias('count')).orderBy('passenger_count')\n",
    "    avg_fare.show()\n",
    "    if 'PULocationID' in df.columns:\n",
    "        top_pu = df.groupBy('PULocationID').agg(count('*').alias('trips')).orderBy(desc('trips')).limit(20)\n",
    "        top_pu.show(20, truncate=False)\n",
    "    return {'trips_by_hour': trips_by_hour, 'avg_fare': avg_fare, 'top_pu': top_pu if 'PULocationID' in df.columns else None, 'clean_df': df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bf572c2-11ca-47a9-b387-7634d37c062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(df):\n",
    "    df1 = df.filter(col('trip_distance') > 0).withColumn('fare_per_mile', col('fare_amount') / col('trip_distance'))\n",
    "    fare_stats = df1.select('fare_per_mile').describe().toPandas()\n",
    "    print(\"Fare per mile stats:\\n\", fare_stats)\n",
    "    from pyspark.sql.functions import dayofweek\n",
    "    dow_hour = df.withColumn('dow', dayofweek(col('tpep_pickup_datetime'))).groupBy('dow', 'pickup_hour').agg(count('*').alias('trips')).orderBy(desc('trips')).limit(20)\n",
    "    dow_hour.show()\n",
    "    summary = df1.groupBy('passenger_count').agg(count('*').alias('trips'), avg('fare_amount').alias('avg_fare'), avg('trip_distance').alias('avg_distance')).orderBy('passenger_count')\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030bac4f-fa35-4c48-81fa-bfecec6a3057",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11fa08b5-17ef-4125-ac44-bcc6e8548d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(aggregates_dict):\n",
    "    trips_by_hour_pdf = aggregates_dict['trips_by_hour'].toPandas()\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(trips_by_hour_pdf['pickup_hour'], trips_by_hour_pdf['trip_count'], marker='o')\n",
    "    plt.title('Trips by Pickup Hour')\n",
    "    plt.xlabel('Hour of Day')\n",
    "    plt.ylabel('Trip Count')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a3e26c1-5889-4186-9ee1-b678c2f47779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(aggregates_dict):\n",
    "    avg_fare_pdf = aggregates_dict['avg_fare'].toPandas()\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.bar(avg_fare_pdf['passenger_count'].astype(str), avg_fare_pdf['avg_fare'])\n",
    "    plt.title('Average Fare by Passenger Count')\n",
    "    plt.xlabel('Passenger Count')\n",
    "    plt.ylabel('Average Fare ($)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7561bdcd-292d-4ae7-a276-c577fdddac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(df_summary, out_dir=os.path.join(DATA_DIR, 'results')):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = os.path.join(out_dir, 'passenger_summary.csv')\n",
    "    print(f\"Saving summary to {out_path}\")\n",
    "    df_summary.coalesce(1).write.mode('overwrite').option('header', True).csv(out_path)\n",
    "    print(\"Saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d4a4481-2802-49e2-a272-ce563e2f5573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def initialize_spark(app_name=\"BigDataAnalysis\"):\n",
    "    \"\"\"\n",
    "    Initialize and return a SparkSession.\n",
    "    \"\"\"\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(app_name) \\\n",
    "        .config(\"spark.driver.memory\", \"4g\") \\\n",
    "        .config(\"spark.executor.memory\", \"4g\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    print(\"Spark session initialized successfully.\")\n",
    "    return spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0af969f3-a586-4dac-8fb1-0a982d8ef364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "def download_if_missing(url, local_path):\n",
    "    \"\"\"\n",
    "    Download a dataset file if it doesn't already exist locally.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(local_path):\n",
    "        print(f\"Downloading dataset from {url}\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, local_path)\n",
    "            print(f\"Download completed: {local_path}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to download dataset: {e}\")\n",
    "    else:\n",
    "        print(f\"Dataset already exists locally at: {local_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5574736c-2cf6-4aa3-87dc-8a6a13edce79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists locally at: /mnt/data/nyc_yellow_taxi\\yellow_tripdata_2023-01.parquet\n",
      "Spark session initialized successfully.\n",
      "Loading parquet from: /mnt/data/nyc_yellow_taxi\\yellow_tripdata_2023-01.parquet\n",
      "Schema:\n",
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      "\n",
      "Total records:\n",
      "3041717\n",
      "+-----------+----------+\n",
      "|pickup_hour|trip_count|\n",
      "+-----------+----------+\n",
      "|0          |84044     |\n",
      "|1          |59165     |\n",
      "|2          |41508     |\n",
      "|3          |27011     |\n",
      "|4          |17477     |\n",
      "|5          |17724     |\n",
      "|6          |43410     |\n",
      "|7          |86313     |\n",
      "|8          |116211    |\n",
      "|9          |130288    |\n",
      "|10         |142658    |\n",
      "|11         |153084    |\n",
      "|12         |168642    |\n",
      "|13         |177379    |\n",
      "|14         |190067    |\n",
      "|15         |194886    |\n",
      "|16         |194267    |\n",
      "|17         |207902    |\n",
      "|18         |214294    |\n",
      "|19         |191289    |\n",
      "|20         |164437    |\n",
      "|21         |160194    |\n",
      "|22         |146069    |\n",
      "|23         |113398    |\n",
      "+-----------+----------+\n",
      "\n",
      "+---------------+------------------+-------+\n",
      "|passenger_count|          avg_fare|  count|\n",
      "+---------------+------------------+-------+\n",
      "|           NULL|20.866240148418168|  71689|\n",
      "|            0.0|16.264045115133555|  51158|\n",
      "|            1.0| 18.17433966556467|2241917|\n",
      "|            2.0|20.571504277321658| 447710|\n",
      "|            3.0| 20.04505567358429| 105436|\n",
      "|            4.0|21.453610797379802|  53124|\n",
      "|            5.0| 17.95432902771243|  42580|\n",
      "|            6.0| 18.04770537335749|  28083|\n",
      "|            7.0| 68.16666666666667|      6|\n",
      "|            8.0| 82.11307692307693|     13|\n",
      "|            9.0|              90.0|      1|\n",
      "+---------------+------------------+-------+\n",
      "\n",
      "+------------+------+\n",
      "|PULocationID|trips |\n",
      "+------------+------+\n",
      "|132         |157336|\n",
      "|237         |147087|\n",
      "|236         |137646|\n",
      "|161         |134443|\n",
      "|186         |108425|\n",
      "|162         |104643|\n",
      "|142         |99575 |\n",
      "|230         |98047 |\n",
      "|138         |88553 |\n",
      "|170         |87739 |\n",
      "|239         |86662 |\n",
      "|163         |84456 |\n",
      "|48          |82723 |\n",
      "|234         |80685 |\n",
      "|141         |80485 |\n",
      "|79          |77386 |\n",
      "|68          |74538 |\n",
      "|107         |67768 |\n",
      "|249         |66855 |\n",
      "|140         |66685 |\n",
      "+------------+------+\n",
      "\n",
      "Fare per mile stats:\n",
      "   summary       fare_per_mile\n",
      "0   count             2998867\n",
      "1    mean  10.276602059193586\n",
      "2  stddev  121.86105665529753\n",
      "3     min                 0.0\n",
      "4     max             40000.0\n",
      "+---+-----------+-----+\n",
      "|dow|pickup_hour|trips|\n",
      "+---+-----------+-----+\n",
      "|  3|         18|36156|\n",
      "|  3|         17|34480|\n",
      "|  5|         18|34160|\n",
      "|  4|         18|32732|\n",
      "|  3|         15|31738|\n",
      "|  3|         16|31305|\n",
      "|  3|         19|31269|\n",
      "|  5|         17|30781|\n",
      "|  3|         14|30383|\n",
      "|  6|         18|30254|\n",
      "|  2|         17|29922|\n",
      "|  6|         17|29869|\n",
      "|  4|         17|29320|\n",
      "|  4|         19|28940|\n",
      "|  6|         19|28865|\n",
      "|  2|         18|28677|\n",
      "|  2|         15|28591|\n",
      "|  5|         19|28473|\n",
      "|  3|         13|28095|\n",
      "|  5|         15|27946|\n",
      "+---+-----------+-----+\n",
      "\n",
      "+---------------+-------+------------------+------------------+\n",
      "|passenger_count|  trips|          avg_fare|      avg_distance|\n",
      "+---------------+-------+------------------+------------------+\n",
      "|           NULL|  64203| 21.18610360886491| 23.42049343488613|\n",
      "|            0.0|  49983| 16.15849828941846| 2.827099213732684|\n",
      "|            1.0|2213927| 18.07143678630944| 3.386773881884802|\n",
      "|            2.0| 443756|20.400846951927683|3.9707537024852257|\n",
      "|            3.0| 104431|19.858918711877095|3.7015739579243587|\n",
      "|            4.0|  52091| 20.87915743602549| 3.893526904839578|\n",
      "|            5.0|  42463|17.965212066975848| 3.298761510020464|\n",
      "|            6.0|  28001|18.043596657262192|3.2647441162815505|\n",
      "|            7.0|      5|              67.8|             5.086|\n",
      "|            8.0|      7| 82.49571428571429|7.9314285714285715|\n",
      "+---------------+-------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving summary to /mnt/data/nyc_yellow_taxi\\results\\passenger_summary.csv\n",
      "Spark session stopped.\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o377.csv.\n: java.lang.RuntimeException: java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory C:\\hadoop does not exist -see https://cwiki.apache.org/confluence/display/HADOOP2/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:789)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:298)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:314)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:1116)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:798)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:838)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:810)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:837)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:810)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:837)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:810)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:988)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356)\r\n\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.setupJob(HadoopMapReduceCommitProtocol.scala:190)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:268)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:306)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:189)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:195)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:117)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:115)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:129)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:402)\r\n\tat org.apache.spark.sql.execution.adaptive.ResultQueryStageExec.$anonfun$doMaterialize$1(QueryStageExec.scala:325)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$4(SQLExecution.scala:322)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:272)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$3(SQLExecution.scala:320)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$2(SQLExecution.scala:316)\r\n\tat java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1439)\r\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:131)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:192)\r\n\tat org.apache.spark.sql.classic.DataFrameWriter.runCommand(DataFrameWriter.scala:622)\r\n\tat org.apache.spark.sql.classic.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:273)\r\n\tat org.apache.spark.sql.classic.DataFrameWriter.saveInternal(DataFrameWriter.scala:241)\r\n\tat org.apache.spark.sql.classic.DataFrameWriter.save(DataFrameWriter.scala:118)\r\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:426)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:578)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1623)\r\n\tSuppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller\r\n\t\tat org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:789)\r\n\t\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:298)\r\n\t\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:314)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:1116)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:798)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:838)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:810)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:837)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:810)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:837)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:810)\r\n\t\tat org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:988)\r\n\t\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356)\r\n\t\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.setupJob(HadoopMapReduceCommitProtocol.scala:190)\r\n\t\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:268)\r\n\t\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:306)\r\n\t\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:189)\r\n\t\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:195)\r\n\t\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:117)\r\n\t\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:115)\r\n\t\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:129)\r\n\t\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:402)\r\n\t\tat org.apache.spark.sql.execution.adaptive.ResultQueryStageExec.$anonfun$doMaterialize$1(QueryStageExec.scala:325)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$4(SQLExecution.scala:322)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:272)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$3(SQLExecution.scala:320)\r\n\t\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$2(SQLExecution.scala:316)\r\n\t\tat java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)\r\n\t\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\t\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t\t... 1 more\r\nCaused by: java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory C:\\hadoop does not exist -see https://cwiki.apache.org/confluence/display/HADOOP2/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:601)\r\n\tat org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:622)\r\n\tat org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:645)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:742)\r\n\tat org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDurationHelper(Configuration.java:1954)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1912)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1885)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)\r\n\tat org.apache.hadoop.util.ShutdownHookManager$HookEntry.<init>(ShutdownHookManager.java:207)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.addShutdownHook(ShutdownHookManager.java:304)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$install$1(ShutdownHookManager.scala:194)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\r\n\tat scala.Option.fold(Option.scala:263)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.install(ShutdownHookManager.scala:195)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks$lzycompute(ShutdownHookManager.scala:55)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks(ShutdownHookManager.scala:53)\r\n\tat org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:159)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<clinit>(ShutdownHookManager.scala:63)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:250)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir(SparkFileUtils.scala:103)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir$(SparkFileUtils.scala:102)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:99)\r\n\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:379)\r\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:961)\r\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:204)\r\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:227)\r\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:96)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1132)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1141)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nCaused by: java.io.FileNotFoundException: Hadoop home directory C:\\hadoop does not exist\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:544)\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:492)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:569)\r\n\t... 27 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpark session stopped.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 16\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     summary\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     15\u001b[0m     visualize(aggregates)\n\u001b[1;32m---> 16\u001b[0m     \u001b[43msave_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     spark\u001b[38;5;241m.\u001b[39mstop()\n",
      "Cell \u001b[1;32mIn[11], line 5\u001b[0m, in \u001b[0;36msave_results\u001b[1;34m(df_summary, out_dir)\u001b[0m\n\u001b[0;32m      3\u001b[0m out_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(out_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassenger_summary.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving summary to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mdf_summary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoalesce\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moverwrite\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mheader\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\sql\\readwriter.py:2146\u001b[0m, in \u001b[0;36mDataFrameWriter.csv\u001b[1;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue, lineSep)\u001b[0m\n\u001b[0;32m   2127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode(mode)\n\u001b[0;32m   2128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(\n\u001b[0;32m   2129\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   2130\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2144\u001b[0m     lineSep\u001b[38;5;241m=\u001b[39mlineSep,\n\u001b[0;32m   2145\u001b[0m )\n\u001b[1;32m-> 2146\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\py4j\\java_gateway.py:1362\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1356\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1357\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1358\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1359\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1361\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1362\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1363\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1365\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1366\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:282\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpy4j\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotocol\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Py4JJavaError\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    284\u001b[0m     converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\py4j\\protocol.py:327\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    325\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o377.csv.\n: java.lang.RuntimeException: java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory C:\\hadoop does not exist -see https://cwiki.apache.org/confluence/display/HADOOP2/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:789)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:298)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:314)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:1116)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:798)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:838)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:810)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:837)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:810)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:837)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:810)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:988)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356)\r\n\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.setupJob(HadoopMapReduceCommitProtocol.scala:190)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:268)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:306)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:189)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:195)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:117)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:115)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:129)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:402)\r\n\tat org.apache.spark.sql.execution.adaptive.ResultQueryStageExec.$anonfun$doMaterialize$1(QueryStageExec.scala:325)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$4(SQLExecution.scala:322)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:272)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$3(SQLExecution.scala:320)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$2(SQLExecution.scala:316)\r\n\tat java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1439)\r\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:131)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:192)\r\n\tat org.apache.spark.sql.classic.DataFrameWriter.runCommand(DataFrameWriter.scala:622)\r\n\tat org.apache.spark.sql.classic.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:273)\r\n\tat org.apache.spark.sql.classic.DataFrameWriter.saveInternal(DataFrameWriter.scala:241)\r\n\tat org.apache.spark.sql.classic.DataFrameWriter.save(DataFrameWriter.scala:118)\r\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:426)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:578)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1623)\r\n\tSuppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller\r\n\t\tat org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:789)\r\n\t\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:298)\r\n\t\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:314)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:1116)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:798)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:838)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:810)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:837)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:810)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:837)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:810)\r\n\t\tat org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:988)\r\n\t\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356)\r\n\t\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.setupJob(HadoopMapReduceCommitProtocol.scala:190)\r\n\t\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:268)\r\n\t\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:306)\r\n\t\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:189)\r\n\t\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:195)\r\n\t\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:117)\r\n\t\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:115)\r\n\t\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:129)\r\n\t\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:402)\r\n\t\tat org.apache.spark.sql.execution.adaptive.ResultQueryStageExec.$anonfun$doMaterialize$1(QueryStageExec.scala:325)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$4(SQLExecution.scala:322)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:272)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$3(SQLExecution.scala:320)\r\n\t\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$2(SQLExecution.scala:316)\r\n\t\tat java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)\r\n\t\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\t\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t\t... 1 more\r\nCaused by: java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory C:\\hadoop does not exist -see https://cwiki.apache.org/confluence/display/HADOOP2/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:601)\r\n\tat org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:622)\r\n\tat org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:645)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:742)\r\n\tat org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDurationHelper(Configuration.java:1954)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1912)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1885)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)\r\n\tat org.apache.hadoop.util.ShutdownHookManager$HookEntry.<init>(ShutdownHookManager.java:207)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.addShutdownHook(ShutdownHookManager.java:304)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$install$1(ShutdownHookManager.scala:194)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\r\n\tat scala.Option.fold(Option.scala:263)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.install(ShutdownHookManager.scala:195)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks$lzycompute(ShutdownHookManager.scala:55)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks(ShutdownHookManager.scala:53)\r\n\tat org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:159)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<clinit>(ShutdownHookManager.scala:63)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:250)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir(SparkFileUtils.scala:103)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir$(SparkFileUtils.scala:102)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:99)\r\n\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:379)\r\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:961)\r\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:204)\r\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:227)\r\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:96)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1132)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1141)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nCaused by: java.io.FileNotFoundException: Hadoop home directory C:\\hadoop does not exist\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:544)\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:492)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:569)\r\n\t... 27 more\r\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    try:\n",
    "        download_if_missing(PARQUET_URL, PARQUET_LOCAL)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "    \n",
    "    spark = initialize_spark()\n",
    "    \n",
    "    try:\n",
    "        df = load_parquet(spark, PARQUET_LOCAL)\n",
    "        df_clean = preprocess(df)\n",
    "        aggregates = perform_eda(df_clean)\n",
    "        summary = analyze(aggregates['clean_df'])\n",
    "        summary.show()\n",
    "        visualize(aggregates)\n",
    "        save_results(summary)\n",
    "    finally:\n",
    "        spark.stop()\n",
    "        print('Spark session stopped.')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d29af35-b2bb-4412-8b46-c0ff56d3467e",
   "metadata": {},
   "source": [
    "# Thank You"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
